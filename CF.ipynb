{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kxwm_U81x3S"
      },
      "source": [
        "Names: Kalyan Kumar Alisetty, Maruthi Sankar Nanduri"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EfUnYad7s5T",
        "outputId": "63dfb5b8-1304-4373-d4ea-8ab086b071d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #This statement helps to connect to the google drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sDOfYby8-ba"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "from numpy import dot\n",
        "from numpy.linalg import norm # importing required packages"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_XDlTpE8zfu",
        "outputId": "82357bf8-6e84-452b-baed-da1f3ae0fc5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ratings = pd.read_csv(\"/content/drive/My Drive/CS5683/training_dataset.csv\") #reading the training dataset into a pandas dataframe\n",
        "ratings.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>movie_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>Kolya (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>L.A. Confidential (1997)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>Heavyweights (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>Legends of the Fall (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>Jackie Brown (1997)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  item_id  rating                  movie_name\n",
              "0      196      242       3                Kolya (1996)\n",
              "1      186      302       3    L.A. Confidential (1997)\n",
              "2       22      377       1         Heavyweights (1994)\n",
              "3      244       51       2  Legends of the Fall (1994)\n",
              "4      166      346       1         Jackie Brown (1997)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHpwru0j-TrB"
      },
      "source": [
        "users = ratings['user_id'].max() # Gives the number of users\n",
        "movies = ratings['item_id'].max() #Gives the number of movies"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUx92T5IG_cT"
      },
      "source": [
        "R = np.empty((movies,users)) #Empty utility matrix with nan values\n",
        "R[:] = np.nan"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4Niqq8S8PwS"
      },
      "source": [
        "R_avg = np.empty((movies,users)) #Empty utility matrix with nan values\n",
        "R_avg[:] = np.nan"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkGLibIFBcWU"
      },
      "source": [
        "path = '/content/drive/My Drive/CS5683/training_dataset.csv' #We can update the matrix iteration using above dataframe also, but its slow than this process of reading each line and updating\n",
        "with open(path) as f:\n",
        "  count = 0\n",
        "  for line in f: #reading each line from the training dataset file\n",
        "    lis = line.split(',') #split the line using comma as it is CSV file\n",
        "    if count > 0: # To avoid the header line\n",
        "      u = int(lis[0])-1 #user ID\n",
        "      m = int(lis[1])-1 # Item ID\n",
        "      r = int(lis[2]) #Rating\n",
        "      R[m,u] = r # updating the utility matrix\n",
        "    count += 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIaZtKvJJdHa",
        "outputId": "db4f3a4c-808b-45fd-a661-cdf535e93480",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for x in range(movies):\n",
        "  avg = np.nanmean(R[x])\n",
        "  R_avg[x] = R[x] - avg # Here we are just calculating the avg of each row in utility matrix and subtracting them from each row and updating those into another matrix which is also utility matrix"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: Mean of empty slice\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2bHK9ERmUwO"
      },
      "source": [
        "R_avg = np.nan_to_num(R_avg) #Replacing the nan in the utility matrix to zeros"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAolh5vWZOPG"
      },
      "source": [
        "def cosine(a,b): # Cosine similarity function\n",
        "  similarity = {} #Cosine Similarity Values storing dictionary\n",
        "  for movie in b: #For each movie\n",
        "    cos_sim = dot(a, R_avg[movie-1])/(norm(a)*norm(R_avg[movie-1])) #Cosine similarity \n",
        "    #print(cos_sim)\n",
        "    if cos_sim > 0.5: #If the cosine similarity is greater than .5\n",
        "      similarity[movie] = cos_sim # add that movie and cosine similarity value to the dictionary\n",
        "  return similarity # return similarity dictionary"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BUkedpmfj55"
      },
      "source": [
        "testpath = '/content/drive/My Drive/CS5683/test_dataset.csv' # Testing dataset path\n",
        "true_rating = [] #To store the original rating\n",
        "pred_rating = [] # To store the predicted rating\n",
        "with open(testpath) as f:\n",
        "  count = 0\n",
        "  for line in f: #reading each line from the training dataset file\n",
        "    lis = line.split(',') #split the line using comma as it is CSV file\n",
        "    num = 0\n",
        "    den = 0\n",
        "    if count > 0: # To avoid the header line\n",
        "      u = int(lis[0])-1 #user ID\n",
        "      m = int(lis[1])-1 # Item ID\n",
        "      r = int(lis[2]) #Rating\n",
        "      other_movies = list(ratings[ratings.user_id == u+1]['item_id']) # Collect the list of movies rating by that user in the line read using the initial dataframe.\n",
        "      similar = cosine(R_avg[m],other_movies) #Sending the ratings of the movie read and also list of movies rated by the user in the line read\n",
        "      #print(similar)\n",
        "      for movie1 in similar: #For each movie in the 50% similar movies\n",
        "        num = num + R[movie1-1][u]*similar[movie1] #Calculate the value of numerator in the predicted rating\n",
        "        den = den + similar[movie1] #Calculate the value of denominator in the predicted rating\n",
        "      true_rating.append(r) #Appending the values of the original rating to the list\n",
        "      if den == 0: #If there is not movie which is atleast 50% similar then I have considered the average rating of that user in the line read\n",
        "        pred_rating.append(np.nanmean(R[:,u]))\n",
        "      else:\n",
        "        pred_rating.append(num/den) # Else the predicted rating calculated using the given formula\n",
        "    count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjbGiuLhuGhv"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error # This method is used to calculate RMSE\n",
        "from math import sqrt\n",
        "def RMSE(y_actual, y_predicted):\n",
        "  rms = sqrt(mean_squared_error(y_actual, y_predicted))\n",
        "  return round(rms,4)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWZrVSceuO0d",
        "outputId": "86d3b0a3-1875-460b-c7cb-68ce564e35a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(RMSE(true_rating,pred_rating)) #RMSE on the test dataset using the cosine similarity metric"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjC1gbQ_d5H_"
      },
      "source": [
        "avg_userrating = [] # We are collecting the average rating of every user into a list\n",
        "for user1 in range(users):\n",
        "  avg_userrating.append(np.nanmean(R[:,user1])) #The average rating is calculate by neglecting the nan values"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqUMPzUHp7qQ"
      },
      "source": [
        "def adj_cosine(a,b): # Calculating the adjusted cosine similarity \n",
        "  adj_similarity = {} #Adjusted Cosine Similarity Values storing dictionary\n",
        "  for adj_movie in b:#For each movie\n",
        "    adjcos_sim = dot(np.subtract(a,avg_userrating), np.subtract(R_avg[adj_movie-1],avg_userrating))/(norm(np.subtract(a,avg_userrating))*norm(np.subtract(R_avg[adj_movie-1],avg_userrating))) #Adjusted Cosine similarity by subtracting corresponding user rating\n",
        "    if adjcos_sim > 0.5: #If the adjusted cosine similarity is greater than .5\n",
        "      adj_similarity[adj_movie] = adjcos_sim # add that movie and adjusted cosine similarity value to the dictionary\n",
        "  return adj_similarity # return similarity dictionary"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjjpwvJqIBbQ"
      },
      "source": [
        "testpath = '/content/drive/My Drive/CS5683/test_dataset.csv' # Testing dataset path\n",
        "true_rating = [] #To store the original rating\n",
        "pred_rating = [] # To store the predicted rating\n",
        "with open(testpath) as f:\n",
        "  count = 0\n",
        "  for line in f: #reading each line from the training dataset file\n",
        "    lis = line.split(',') #split the line using comma as it is CSV file\n",
        "    num = 0\n",
        "    den = 0\n",
        "    if count > 0: # To avoid the header line\n",
        "      u = int(lis[0])-1 #user ID\n",
        "      m = int(lis[1])-1 # Item ID\n",
        "      r = int(lis[2]) # Rating\n",
        "      other_movies = list(ratings[ratings.user_id == u+1]['item_id']) # Collect the list of movies rating by that user in the line read using the initial dataframe.\n",
        "      adj_similar = adj_cosine(R_avg[m],other_movies) #Sending the ratings of the movie read and also list of movies rated by the user in the line read\n",
        "      for movie1 in adj_similar: #For each movie in the 50% similar movies\n",
        "        num = num + R[movie1-1][u]*adj_similar[movie1] #Calculate the value of numerator in the predicted rating\n",
        "        den = den + adj_similar[movie1] #Calculate the value of denominator in the predicted rating using the given formula\n",
        "      true_rating.append(r) #Appending the values of the original rating to the list\n",
        "      if den == 0: #If there is not movie which is atleast 50% similar then I have considered the average rating of that user in the line read\n",
        "        pred_rating.append(np.nanmean(R[:,u]))\n",
        "      else: # Else the predicted rating calculated using the given formula\n",
        "        pred_rating.append(num/den)\n",
        "      #pred_rating.append(num/den)\n",
        "    count += 1"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUFaIOJkl2iD",
        "outputId": "5a0e4ecb-7b42-4ae1-a47b-86015e7d26d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(RMSE(true_rating,pred_rating))  #RMSE on the test dataset using the cosine similarity metric"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhFiMWUF2EUg"
      },
      "source": [
        "**Performance:** Maruthi Sankar Nanduri has implementation Cosine similarity and Kalyan Kumar Alisetty has implemented the code for adjusted cosine similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaXnU6M42Zr3"
      },
      "source": [
        "**Comparision of the two metrics models(Cosine and Adjusted Cosine):** The values for the RMSE on the test dataset using both the methods are almost the same.But, the cosine similarity has little bit of edge over the adjusted cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7Sw-shR1P3q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNaBG6gq1QMF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agb2zJnR1QXW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2K7M0yw1QeR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPkzfg7C1Qa2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfzBJk361QPr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuGSq6qf1QET"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}